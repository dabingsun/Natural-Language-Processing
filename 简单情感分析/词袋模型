1、自然语言处理的几个核心问题

    怎么表示单词，句子
    怎么表示单词或者句子的意思（语意信息）？
    怎么衡量单词之间，句子之间的相似度？

2、词袋模型

词袋模型（Bag-of-word Model）是一种常用的单词表示方法。

假设我们辞典里有六个单词：[今天，我们，去，游泳，明天，跑步]

每个单词的表示：

    我们    [1,0,0,0,0,0]
    去       [0,1,0,0,0,0]
    游泳   [0,0,1,0,0,0]
    今天   [0,0,0,1,0,0]
    你们   [0,0,0,0,1,0]
    跑步   [0,0,0,0,0,1]

句子的表示：eg我们今天去游泳：[1,1,1,1,0,0]

     2.1 怎么计算两个单词、句子之间的相似度？

           即怎么计算两个向量之间的距离，有很多种方法，欧氏距离、曼哈顿距离、切比雪夫距离、闵可夫斯基距离、标准化欧氏距离、夹角余弦等，这里暂介绍两种方法：欧式距离，和余弦相似度

          2.1.1 欧式距离（数值越小，相似度越大）

                  欧式距离源自N维欧氏空间中两点x1,x2的距离公式

                 

           2.1.2   余弦相似度（数值越大，相似度越大）

                   余弦相似度，又称为余弦相似性，是通过计算两个向量的夹角余弦值来评估他们的相似度。0度角的余弦值是1，而其他任何角度的余弦值都不大于1；并且其最小值是-1。 

余弦相似度通常用于正空间，因此给出的值为0到1之间。

 

 

                ||A||为向量A的范数，向量的模是绝对值在二维和三维空间的推广，可以认为就是向量的长度。推广到高维空间中称为范数。

                

2.2    词袋模型的缺点

         2.2.1    不能计算词的相似度

    我们    [1,0,0,0,0,0]
    去       [0,1,0,0,0,0]
    游泳   [0,0,1,0,0,0]
    今天   [0,0,0,1,0,0]
    你们   [0,0,0,0,1,0]
    跑步   [0,0,0,0,0,1]         

以上文的辞典为例，     （我们，游泳），和（游泳，跑步）之间的相似度是不同的，但是计算其向量距离得到的结果是相同的。

      2.2.1   Sparsity  稀疏性

        这里我们的辞典中有六个词，每个向量为六维的，但是在应用中，辞典中的词会很多，比如一百万个，那么此时每个向量就是一百万维的，但是每个向量中只有一个1，其他参数全为0，含有信息量非常稀疏。

 

3、为了克服词袋模型的缺点，我们提出了词向量表示方法

这样就可以计算词的相关性，当辞典规模较大时，也可以将每个词的向量维度控制在一定范围，不会出现维度灾难。 

经过深度学习模型训练后，把相似的词的赋予较相近的向量值。
